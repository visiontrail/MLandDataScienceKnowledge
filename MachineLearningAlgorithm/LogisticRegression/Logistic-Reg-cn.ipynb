{"cells":[{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["# 用 Python 进行逻辑回归\n","\n","预计所需时间：**25** 分钟\n","\n","## 目标\n","完成本实验后，你将能够：\n","\n","* 使用scikit-learn的逻辑回归进行分类\n","* 理解混淆矩阵"]},{"cell_type":"markdown","metadata":{},"source":["在本笔记本中，你将学习逻辑回归，然后你将为一家电信公司创建一个模型，以预测其客户何时会流失到竞争对手那里，从而使他们能够采取一些措施来留住客户。"]},{"cell_type":"markdown","metadata":{},"source":["<h1>目录</h1>\n","\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","    <ol>\n","        <li><a href=\"#关于数据集\">关于数据集</a></li>\n","        <li><a href=\"#数据预处理和选择\">数据预处理和选择</a></li>\n","        <li><a href=\"#建模\">建模</a></li>\n","        <li><a href=\"#评估\">评估</a></li>\n","        <li><a href=\"#练习\">练习</a></li>\n","    </ol>\n","</div>\n","<br>\n","<hr>\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["<a id=\"ref1\"></a>\n","## 线性回归和逻辑回归的区别是什么？\n","\n","线性回归适用于估计连续值（例如估计房价），但它并不是预测观察数据点类别的最佳工具。为了估计数据点的类别，我们需要一些指导性算法用于评估该数据点<b>最可能类别（Class）</b>。为此，我们使用<b>逻辑回归</b>。\n","\n","<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n","回顾线性回归:\n","\n","如你所知，<b>线性回归</b>找到一个函数，将连续的因变量<b>y</b>与一些预测变量（自变量$x_1$、$x_2$等）联系起来。例如，简单线性回归假设一个如下形式的函数：\n","\n","$$\n","y = \\theta_0 + \\theta_1  x_1 + \\theta_2  x_2 + \\cdots\n","$$\n","\n","并找到参数$\\theta_0、\\theta_1、\\theta_2$等的值，其中$\\theta_0$是“截距”。它一般可以表示为：<br><br>\n","\n","$$\n","ℎ_\\theta(𝑥) = \\theta^TX\n","$$\n","<p></p>\n","\n","</div>\n","\n","逻辑回归是线性回归的一种变体，适用于当观察到的因变量<b>y</b>是分类变量时。它生成一个公式，将独立变量作为函数来预测类别标签的概率。\n","\n","逻辑回归通过将线性回归函数转化为概率来拟合一个特殊的S形曲线，该转换使用以下函数，这个函数称为S型函数𝜎：\n","$$\n","ℎ_\\theta(𝑥) = \\sigma({\\theta^TX}) =  \\frac {e^{(\\theta_0 + \\theta_1  x_1 + \\theta_2  x_2 +...)}}{1 + e^{(\\theta_0 + \\theta_1  x_1 + \\theta_2  x_2 +\\cdots)}}\n","$$\n","或者：\n","$$\n","ProbabilityOfaClass_1 =  P(Y=1|X) = \\sigma({\\theta^TX}) = \\frac{e^{\\theta^TX}}{1+e^{\\theta^TX}} \n","$$\n","\n","在这个方程中，${\\theta^TX}$是回归结果（变量加权系数的总和），`exp`是指数函数，而$\\sigma(\\theta^TX)$是S型函数或[逻辑函数](http://en.wikipedia.org/wiki/Logistic_function?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2023-01-01)，也称为逻辑曲线。这是一种常见的“S”形（S型曲线）。\n","\n","简而言之，逻辑回归通过逻辑/ S 型函数处理输入，然后将结果视为概率：\n","\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/images/mod_ID_24_final.png\" width=\"400\" align=\"center\">\n","\n","\n","逻辑回归算法的目标是找到最优参数θ，使得$ℎ_\\theta(𝑥)$ = $\\sigma({\\theta^TX})$，从而使模型最佳预测每个案例的类别。\n"]},{"cell_type":"markdown","metadata":{},"source":["### 使用逻辑回归分析客户流失\n","一家电信公司担心有大量客户从其固定电话业务转向有线电视竞争对手。他们需要了解哪些客户正在流失。想象你是这家公司的分析师，你需要找出哪些客户在流失以及他们离开的原因。"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"shellscript"}},"outputs":[],"source":["pip install scikit-learn==0.23.1"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["第一步，引入依赖"]},{"cell_type":"code","execution_count":1,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["import pandas as pd\n","import pylab as pl\n","import numpy as np\n","import scipy.optimize as opt\n","from sklearn import preprocessing\n","%matplotlib inline \n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["<h2 id=\"about_dataset\">关于数据集</h2>\n","我们将使用一个电信数据集来预测客户流失。这是一个历史客户数据集，其中每一行代表一个客户。数据相对容易理解，并且你可以立即发现一些可用的见解。通常来说，留住现有客户比获取新客户的成本更低，因此本次分析的重点是预测哪些客户会留在公司。\n","\n","该数据集提供的信息有助于你预测哪些行为将帮助你留住客户。你可以分析所有相关的客户数据，并制定针对性的客户保留计划。\n","\n","数据集包括以下信息：\n","\n","- 在上个月流失的客户——该列称为Churn\n","- 每位客户签约的服务——电话、多条线路、互联网、在线安全、在线备份、设备保护、技术支持、流媒体电视和电影\n","- 客户账户信息——客户持续时间、合同类型、付款方式、无纸化账单、月收费和总收费\n","- 客户的人口统计信息——性别、年龄范围、是否有伴侣和受抚养人"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["### 加载电信客户流失数据（已下载）\n","Telco Churn 是一个假设的数据文件，涉及一家电信公司减少客户流失的努力。每个案例对应一个单独的客户，记录了各种人口统计和服务使用信息。在处理数据之前，必须使用URL获取ChurnData.csv。\n","\n","要下载数据，我们将使用 `!wget` 从 IBM 对象存储中下载它。"]},{"cell_type":"code","execution_count":null,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[],"source":["#Click here and press Shift+Enter\n","!wget -O ChurnData.csv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/ChurnData.csv"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["## 从CSV文件加载数据"]},{"cell_type":"code","execution_count":2,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tenure</th>\n","      <th>age</th>\n","      <th>address</th>\n","      <th>income</th>\n","      <th>ed</th>\n","      <th>employ</th>\n","      <th>equip</th>\n","      <th>callcard</th>\n","      <th>wireless</th>\n","      <th>longmon</th>\n","      <th>...</th>\n","      <th>pager</th>\n","      <th>internet</th>\n","      <th>callwait</th>\n","      <th>confer</th>\n","      <th>ebill</th>\n","      <th>loglong</th>\n","      <th>logtoll</th>\n","      <th>lninc</th>\n","      <th>custcat</th>\n","      <th>churn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11.0</td>\n","      <td>33.0</td>\n","      <td>7.0</td>\n","      <td>136.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>4.40</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.482</td>\n","      <td>3.033</td>\n","      <td>4.913</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>33.0</td>\n","      <td>33.0</td>\n","      <td>12.0</td>\n","      <td>33.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>9.45</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.246</td>\n","      <td>3.240</td>\n","      <td>3.497</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23.0</td>\n","      <td>30.0</td>\n","      <td>9.0</td>\n","      <td>30.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.30</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.841</td>\n","      <td>3.240</td>\n","      <td>3.401</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38.0</td>\n","      <td>35.0</td>\n","      <td>5.0</td>\n","      <td>76.0</td>\n","      <td>2.0</td>\n","      <td>10.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>6.05</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.800</td>\n","      <td>3.807</td>\n","      <td>4.331</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.0</td>\n","      <td>35.0</td>\n","      <td>14.0</td>\n","      <td>80.0</td>\n","      <td>2.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>7.10</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.960</td>\n","      <td>3.091</td>\n","      <td>4.382</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 28 columns</p>\n","</div>"],"text/plain":["   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n","0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n","1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n","2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n","3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n","4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n","\n","   longmon  ...  pager  internet  callwait  confer  ebill  loglong  logtoll  \\\n","0     4.40  ...    1.0       0.0       1.0     1.0    0.0    1.482    3.033   \n","1     9.45  ...    0.0       0.0       0.0     0.0    0.0    2.246    3.240   \n","2     6.30  ...    0.0       0.0       0.0     1.0    0.0    1.841    3.240   \n","3     6.05  ...    1.0       1.0       1.0     1.0    1.0    1.800    3.807   \n","4     7.10  ...    0.0       0.0       1.0     1.0    0.0    1.960    3.091   \n","\n","   lninc  custcat  churn  \n","0  4.913      4.0    1.0  \n","1  3.497      1.0    1.0  \n","2  3.401      3.0    0.0  \n","3  4.331      4.0    0.0  \n","4  4.382      3.0    0.0  \n","\n","[5 rows x 28 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["churn_df = pd.read_csv(\"ChurnData.csv\")\n","churn_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"数据预处理和选择\">数据预处理和选择</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["让我们选择一些用于建模的特征。同时，我们将目标数据类型更改为整数，因为这是sklearn算法的要求："]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tenure</th>\n","      <th>age</th>\n","      <th>address</th>\n","      <th>income</th>\n","      <th>ed</th>\n","      <th>employ</th>\n","      <th>equip</th>\n","      <th>callcard</th>\n","      <th>wireless</th>\n","      <th>churn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11.0</td>\n","      <td>33.0</td>\n","      <td>7.0</td>\n","      <td>136.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>33.0</td>\n","      <td>33.0</td>\n","      <td>12.0</td>\n","      <td>33.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23.0</td>\n","      <td>30.0</td>\n","      <td>9.0</td>\n","      <td>30.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38.0</td>\n","      <td>35.0</td>\n","      <td>5.0</td>\n","      <td>76.0</td>\n","      <td>2.0</td>\n","      <td>10.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.0</td>\n","      <td>35.0</td>\n","      <td>14.0</td>\n","      <td>80.0</td>\n","      <td>2.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   tenure   age  address  income   ed  employ  equip  callcard  wireless  \\\n","0    11.0  33.0      7.0   136.0  5.0     5.0    0.0       1.0       1.0   \n","1    33.0  33.0     12.0    33.0  2.0     0.0    0.0       0.0       0.0   \n","2    23.0  30.0      9.0    30.0  1.0     2.0    0.0       0.0       0.0   \n","3    38.0  35.0      5.0    76.0  2.0    10.0    1.0       1.0       1.0   \n","4     7.0  35.0     14.0    80.0  2.0    15.0    0.0       1.0       0.0   \n","\n","   churn  \n","0      1  \n","1      1  \n","2      0  \n","3      0  \n","4      0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["churn_df = churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip',   'callcard', 'wireless','churn']]\n","churn_df['churn'] = churn_df['churn'].astype('int')\n","churn_df.head()"]},{"cell_type":"markdown","metadata":{"button":true,"new_sheet":true,"run_control":{"read_only":false}},"source":["## 练习\n","该数据集中总共有多少行和多少列？列的名称是什么？"]},{"cell_type":"code","execution_count":4,"metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"outputs":[{"data":{"text/plain":["(200, 10)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# write your code here\n","churn_df.shape"]},{"cell_type":"markdown","metadata":{},"source":["将给定数据（X和y）转换为 NumPy 数组"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 11.,  33.,   7., 136.,   5.,   5.,   0.],\n","       [ 33.,  33.,  12.,  33.,   2.,   0.,   0.],\n","       [ 23.,  30.,   9.,  30.,   1.,   2.,   0.],\n","       [ 38.,  35.,   5.,  76.,   2.,  10.,   1.],\n","       [  7.,  35.,  14.,  80.,   2.,  15.,   0.]])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["X = np.asarray(churn_df[['tenure', 'age', 'address', 'income', 'ed', 'employ', 'equip']])\n","X[0:5]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 1, 0, 0, 0])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["y = np.asarray(churn_df['churn'])\n","y [0:5]"]},{"cell_type":"markdown","metadata":{},"source":["此外，我们对数据集进行归一化处理："]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-1.13518441, -0.62595491, -0.4588971 ,  0.4751423 ,  1.6961288 ,\n","        -0.58477841, -0.85972695],\n","       [-0.11604313, -0.62595491,  0.03454064, -0.32886061, -0.6433592 ,\n","        -1.14437497, -0.85972695],\n","       [-0.57928917, -0.85594447, -0.261522  , -0.35227817, -1.42318853,\n","        -0.92053635, -0.85972695],\n","       [ 0.11557989, -0.47262854, -0.65627219,  0.00679109, -0.6433592 ,\n","        -0.02518185,  1.16316   ],\n","       [-1.32048283, -0.47262854,  0.23191574,  0.03801451, -0.6433592 ,\n","         0.53441472, -0.85972695]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn import preprocessing\n","# 通过缩放来标准化特征，将缩放（标准化）应用于数据 X\n","X = preprocessing.StandardScaler().fit(X).transform(X)\n","X[0:5]"]},{"cell_type":"markdown","metadata":{},"source":["## 训练，测试数据\n"]},{"cell_type":"markdown","metadata":{},"source":["拆分训练数据和测试数据\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set: (160, 7) (160,)\n","Test set: (40, 7) (40,)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n","print ('Train set:', X_train.shape,  y_train.shape)\n","print ('Test set:', X_test.shape,  y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"建模\">建模</h2>"]},{"cell_type":"markdown","metadata":{},"source":["让我们使用Scikit-learn包中的 __LogisticRegression__ 构建我们的模型。此函数实现逻辑回归，并且可以使用不同的数值优化器来找到参数，包括‘newton-cg’、‘lbfgs’、‘liblinear’、‘sag’、‘saga’求解器。如果你在网上搜索，可以找到关于这些优化器优缺点的详细信息。\n","\n","Scikit-learn中的逻辑回归版本支持正则化。正则化是一种用于解决机器学习模型过拟合问题的技术。__C__ 参数表示 __正则化强度的倒数__，它必须是一个正浮点数。较小的值表示较强的正则化。\n","现在让我们用训练集来拟合我们的模型："]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-1 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-1 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-1 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-1 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-1 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-1 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-1 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-1 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-1 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-1 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-1 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-1 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-1 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-1 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-1 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-1 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-1 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-1 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-1 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=0.01, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"],"text/plain":["LogisticRegression(C=0.01, solver='liblinear')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n","LR"]},{"cell_type":"markdown","metadata":{},"source":["现在可以使用测试数据进行预测"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["yhat = LR.predict(X_test)\n","yhat"]},{"cell_type":"markdown","metadata":{},"source":["__predict_proba__ 返回所有类别的估计值，按类别标签排序。因此，第一列是类别0的概率P(Y=0|X)，第二列是类别1的概率P(Y=1|X)："]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.54132919, 0.45867081],\n","       [0.60593357, 0.39406643],\n","       [0.56277713, 0.43722287],\n","       [0.63432489, 0.36567511],\n","       [0.56431839, 0.43568161],\n","       [0.55386646, 0.44613354],\n","       [0.52237207, 0.47762793],\n","       [0.60514349, 0.39485651],\n","       [0.41069572, 0.58930428],\n","       [0.6333873 , 0.3666127 ],\n","       [0.58068791, 0.41931209],\n","       [0.62768628, 0.37231372],\n","       [0.47559883, 0.52440117],\n","       [0.4267593 , 0.5732407 ],\n","       [0.66172417, 0.33827583],\n","       [0.55092315, 0.44907685],\n","       [0.51749946, 0.48250054],\n","       [0.485743  , 0.514257  ],\n","       [0.49011451, 0.50988549],\n","       [0.52423349, 0.47576651],\n","       [0.61619519, 0.38380481],\n","       [0.52696302, 0.47303698],\n","       [0.63957168, 0.36042832],\n","       [0.52205164, 0.47794836],\n","       [0.50572852, 0.49427148],\n","       [0.70706202, 0.29293798],\n","       [0.55266286, 0.44733714],\n","       [0.52271594, 0.47728406],\n","       [0.51638863, 0.48361137],\n","       [0.71331391, 0.28668609],\n","       [0.67862111, 0.32137889],\n","       [0.50896403, 0.49103597],\n","       [0.42348082, 0.57651918],\n","       [0.71495838, 0.28504162],\n","       [0.59711064, 0.40288936],\n","       [0.63808839, 0.36191161],\n","       [0.39957895, 0.60042105],\n","       [0.52127638, 0.47872362],\n","       [0.65975464, 0.34024536],\n","       [0.5114172 , 0.4885828 ]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["yhat_prob = LR.predict_proba(X_test)\n","yhat_prob"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"evaluation\">Evaluation</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["### jaccard index\n","Let's try the jaccard index for accuracy evaluation. we can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import jaccard_score\n","jaccard_score(y_test, yhat,pos_label=0)"]},{"cell_type":"markdown","metadata":{},"source":["### confusion matrix\n","Another way of looking at the accuracy of the classifier is to look at __confusion matrix__.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","import itertools\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","print(confusion_matrix(y_test, yhat, labels=[1,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compute confusion matrix\n","cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\n","np.set_printoptions(precision=2)\n","\n","\n","# Plot non-normalized confusion matrix\n","plt.figure()\n","plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')"]},{"cell_type":"markdown","metadata":{},"source":["Let's look at first row. The first row is for customers whose actual churn value in the test set is 1.\n","As you can calculate, out of 40 customers, the churn value of 15 of them is 1. \n","Out of these 15 cases, the classifier correctly predicted 6 of them as 1, and 9 of them as 0. \n","\n","This means, for 6 customers, the actual churn value was 1 in test set and classifier also correctly predicted those as 1. However, while the actual label of 9 customers was 1, the classifier predicted those as 0, which is not very good. We can consider it as the error of the model for first row.\n","\n","What about the customers with churn value 0? Lets look at the second row.\n","It looks like  there were 25 customers whom their churn value were 0. \n","\n","\n","The classifier correctly predicted 24 of them as 0, and one of them wrongly as 1. So, it has done a good job in predicting the customers with churn value 0. A good thing about the confusion matrix is that it shows the model’s ability to correctly predict or separate the classes.  In a specific case of the binary classifier, such as this example,  we can interpret these numbers as the count of true positives, false positives, true negatives, and false negatives. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print (classification_report(y_test, yhat))\n"]},{"cell_type":"markdown","metadata":{},"source":["Based on the count of each section, we can calculate precision and recall of each label:\n","\n","\n","- __Precision__ is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP / (TP + FP)\n","\n","- __Recall__ is the true positive rate. It is defined as: Recall =  TP / (TP + FN)\n","\n","    \n","So, we can calculate the precision and recall of each class.\n","\n","__F1 score:__\n","Now we are in the position to calculate the F1 scores for each label based on the precision and recall of that label. \n","\n","The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. It is a good way to show that a classifer has a good value for both recall and precision.\n","\n","\n","Finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 0.72 in our case.\n"]},{"cell_type":"markdown","metadata":{},"source":["### log loss\n","Now, let's try __log loss__ for evaluation. In logistic regression, the output can be the probability of customer churn is yes (or equals to 1). This probability is a value between 0 and 1.\n","Log loss( Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import log_loss\n","log_loss(y_test, yhat_prob)"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"practice\">Practice</h2>\n","Try to build Logistic Regression model again for the same dataset, but this time, use different __solver__ and __regularization__ values? What is new __logLoss__ value?\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# write your code here\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<details><summary>Click here for the solution</summary>\n","\n","```python\n","LR2 = LogisticRegression(C=0.01, solver='sag').fit(X_train,y_train)\n","yhat_prob2 = LR2.predict_proba(X_test)\n","print (\"LogLoss: : %.2f\" % log_loss(y_test, yhat_prob2))\n","\n","```\n","\n","</details>\n","\n"]},{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["<h2>Want to learn more?</h2>\n","\n","IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: <a href=\"https://www.ibm.com/analytics/spss-statistics-software?utm_source=Exinfluencer&utm_content=000026UJ&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2023-01-01&utm_medium=Exinfluencer&utm_term=10006555\">SPSS Modeler</a>\n","\n","Also, you can use Watson Studio to run these notebooks faster with bigger datasets. Watson Studio is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Watson Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Watson Studio users today with a free account at <a href=\"https://www.ibm.com/cloud/watson-studio?utm_source=Exinfluencer&utm_content=000026UJ&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2023-01-01&utm_medium=Exinfluencer&utm_term=10006555\">Watson Studio</a>\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Thank you for completing this lab!\n","\n","\n","## Author\n","\n","Saeed Aghabozorgi\n","\n","\n","### Other Contributors\n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2023-01-01\">Joseph Santarcangelo</a>\n","\n","\n","\n","\n","## Change Log\n","\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2021-01-21  | 2.2  | Lakshmi  |  Updated sklearn library|\n","| 2020-11-03  | 2.1  | Lakshmi  |  Updated URL of csv |\n","| 2020-08-27  | 2.0  | Lavanya  |  Moved lab to course repo in GitLab |\n","|   |   |   |   |\n","|   |   |   |   |\n","\n","\n","## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":2}
